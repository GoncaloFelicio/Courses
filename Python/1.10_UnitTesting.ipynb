{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d092f33c-65b3-45f0-a03e-da6b8ae33a3c",
   "metadata": {},
   "source": [
    "# Notes on Python\n",
    "## Examples for reference, tips, Best Practices\n",
    "\n",
    "Based on the Course: Core Python (Unit Testing with Python) at PluralSight\n",
    "\n",
    "For more examples of code and detailed explanations see the UnitTestProject folder\n",
    "\n",
    "Author: Gonçalo Felício  \n",
    "Date: 04/2022  \n",
    "Provided by: ISIWAY\n",
    "\n",
    "Something like a pocketbook to come to for quick references, examples, and tips of best practices, compiled with my own preferences  \n",
    "Loosely divided by subject, and with some degree, by the respective modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f207a-c1cc-4abc-9e35-317c955ba2fb",
   "metadata": {},
   "source": [
    "## Unit Tests\n",
    "Start Unit testing your programs now!\n",
    "\n",
    "Unit testing is creating tests that verify our code works the way we think it should  \n",
    "This is more crucial with complex programs that work with several classes and functions, although its a great practice to always use  \n",
    "Sometimes unit testing looks very redundant, but it is actually super important, don't be lazy and ignore tests ever\n",
    "\n",
    "There are different modules that can be used to perform unit testing such as pytest, doctest and unittest. These modules have their advantages and disadantages depending on the situation\n",
    "\n",
    "Tip: I suggest using the pytest package, great readability and ease of use for python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154be20e-0905-4eb9-a380-323d18ac8fc2",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "**Test Case**: A test case should exercise a unit of code and check it works correctly. Each test case is capable of running independently and does not create any results or effects. Even if test cases are applied to the same unit of code, they should work as many times as wanted, without affeccting the other tests\n",
    "\n",
    "**Test Runner**: Test runner is a program that runs the test cases and reports wether they pass or not. Using the unittest model is very easy to run from the command line, although we can also use the test runner built in to IDE's\n",
    "\n",
    "**Test Suite**: Is a number of test cases that are executed together when running a test runner. The test suite can have tests regarding many different classes and functions in the same project, and should work regardless of the test cases or test runner used\n",
    "\n",
    "**Test Fixture**: A test fixture is a unit of code that must always be run when running the test suite. Usually this means setUp method and a tearDown method. The purpose of setUp is to refactor operations that the several other test cases would have to perform, if it was not defined. The tearDown is meant to release resources that the setUp has allocated, like closing a database connection, for example. It works like the *try..finally*, running even if a etst case raises an exception.\n",
    "\n",
    "**Test Case Design**: the design of test cases is very important for functionality and for readability  \n",
    "The name of the test cases should be extremely clear on what is being tested, even if it leads to rather long names  \n",
    "\n",
    "Test cases should also be organized in the following 3 logical blocks (only), even if it leads to many small test cases:  \n",
    ">Arrange - Act - Assert\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc72932-d68b-4e39-95a1-5e62927d85f3",
   "metadata": {},
   "source": [
    "Unit testing can be applied in different ways:\n",
    "\n",
    "Test first: create all the test cases first then write the program that passes the test cases previously defined\n",
    "\n",
    "Test last: the opposite, write the full program, then write the test cases and then run the test runner\n",
    "\n",
    "#### Test Driven \n",
    "Test driven has already been talked in other notes. This is mixing the writting of test cases and production code that passes the tests until no more test cases can be thought up. Also including refactoring tasks after each test passes, whenever the opportunity is found\n",
    "\n",
    "Tip: Use the Test Driven Design process as it leads to the best productivity and overall best results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604e0c4-90c7-463f-bae7-44313aedf186",
   "metadata": {},
   "source": [
    "**Continuous Integration** is the process of commiting your work often during development, at least 2 times a day, as this leads to best environment when working in group. This is also helped with using a built automation server that checks all the tests on each addition to the production code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b6f8a-58e9-443a-99d1-d84b99d6093c",
   "metadata": {},
   "source": [
    "Tip: The most important thing is to write test cases often when developing code and to share it with the other developers that work on the same code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba409d-2d1f-43a3-9f88-532afff5bb7d",
   "metadata": {},
   "source": [
    "### Pytest\n",
    "Pytest is the recommended module for python as it is the most readable with least boilerplate\n",
    "Running tests suites however is best using IDE's not jupyter notebooks, as its easier and realistic of production code  \n",
    "An alternative is to use other third party libraries for this purpose, like ipytest\n",
    "\n",
    "Another way is to use doctest or unitest and run using the last cell of the notebook  \n",
    "doctest.testmod(verbose=True)  \n",
    "or  \n",
    "unittest.main(argv=[''], verbosity=2, exit=False)\n",
    "\n",
    "\n",
    "\n",
    "Small but powerful example from the phonebook class of pytest fucntionalities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "478539c8-6194-4e57-8d66-098ed04c2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class Phonebook:\n",
    "\n",
    "    def __init__(self, cache_directory):\n",
    "        self.numbers = {}\n",
    "        self.filename = os.path.join(cache_directory, \"phonebook.txt\")\n",
    "        self.cache = open(self.filename, \"w\")\n",
    "\n",
    "    def add(self, name, number):\n",
    "        self.numbers[name] = number\n",
    "\n",
    "    def lookup(self, name):\n",
    "        return self.numbers[name]\n",
    "\n",
    "    def names(self):\n",
    "        return set(self.numbers.keys())\n",
    "\n",
    "    def clear(self):\n",
    "        self.cache.close()\n",
    "        os.remove(self.filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121a195b-4a0d-403c-9802-7ee08ca2ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this descriptor is a fixture to create an empty phonebook\n",
    "# tempdir is another fixture that creates and clears the temporary files \n",
    "@pytest.fixture\n",
    "def phonebook(tmpdir):\n",
    "    \"Provides an empty Phonebook\"\n",
    "    return Phonebook(tmpdir)\n",
    "\n",
    "# the simplest test case for the lookup method\n",
    "def test_lookup_by_name(phonebook):\n",
    "    phonebook.add(\"Bob\", \"1234\")\n",
    "    assert \"1234\" == phonebook.lookup(\"Bob\")\n",
    "\n",
    "# Remaining test cases for names method and lookup method\n",
    "def test_phonebook_contains_all_names(phonebook):\n",
    "    phonebook.add(\"Bob\", \"1234\")\n",
    "    assert \"Bob\" in phonebook.names()\n",
    "\n",
    "# using context manager for exception test case\n",
    "def test_missing_name_raises_error(phonebook):\n",
    "    with pytest.raises(KeyError):\n",
    "        phonebook.lookup(\"Bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bebf98ea-9c6a-4cb5-814e-290d1d6a5200",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.9.11, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: C:\\Users\\goncalo.felicio\\Documents\\GitHub\\JourneyToDataEngineer\\Python\n",
      "plugins: anyio-3.5.0\n",
      "collected 0 items / 1 error\n",
      "cache -- ...\\_pytest\\cacheprovider.py:510\n",
      "    Return a cache object that can persist state between testing sessions.\n",
      "\n",
      "capsys -- ...\\_pytest\\capture.py:878\n",
      "    Enable text capturing of writes to ``sys.stdout`` and ``sys.stderr``.\n",
      "\n",
      "capsysbinary -- ...\\_pytest\\capture.py:895\n",
      "    Enable bytes capturing of writes to ``sys.stdout`` and ``sys.stderr``.\n",
      "\n",
      "capfd -- ...\\_pytest\\capture.py:912\n",
      "    Enable text capturing of writes to file descriptors ``1`` and ``2``.\n",
      "\n",
      "capfdbinary -- ...\\_pytest\\capture.py:929\n",
      "    Enable bytes capturing of writes to file descriptors ``1`` and ``2``.\n",
      "\n",
      "doctest_namespace [session scope] -- ...\\_pytest\\doctest.py:731\n",
      "    Fixture that returns a :py:class:`dict` that will be injected into the\n",
      "    namespace of doctests.\n",
      "\n",
      "pytestconfig [session scope] -- ...\\_pytest\\fixtures.py:1334\n",
      "    Session-scoped fixture that returns the session's :class:`pytest.Config`\n",
      "    object.\n",
      "\n",
      "record_property -- ...\\_pytest\\junitxml.py:282\n",
      "    Add extra properties to the calling test.\n",
      "\n",
      "record_xml_attribute -- ...\\_pytest\\junitxml.py:305\n",
      "    Add extra xml attributes to the tag for the calling test.\n",
      "\n",
      "record_testsuite_property [session scope] -- ...\\_pytest\\junitxml.py:343\n",
      "    Record a new ``<property>`` tag as child of the root ``<testsuite>``.\n",
      "\n",
      "tmpdir_factory [session scope] -- ...\\_pytest\\legacypath.py:295\n",
      "    Return a :class:`pytest.TempdirFactory` instance for the test session.\n",
      "\n",
      "tmpdir -- ...\\_pytest\\legacypath.py:302\n",
      "    Return a temporary directory path object which is unique to each test\n",
      "    function invocation, created as a sub directory of the base temporary\n",
      "    directory.\n",
      "\n",
      "caplog -- ...\\_pytest\\logging.py:487\n",
      "    Access and control log capturing.\n",
      "\n",
      "monkeypatch -- ...\\_pytest\\monkeypatch.py:29\n",
      "    A convenient fixture for monkey-patching.\n",
      "\n",
      "recwarn -- ...\\_pytest\\recwarn.py:29\n",
      "    Return a :class:`WarningsRecorder` instance that records all warnings emitted by test functions.\n",
      "\n",
      "tmp_path_factory [session scope] -- ...\\_pytest\\tmpdir.py:183\n",
      "    Return a :class:`pytest.TempPathFactory` instance for the test session.\n",
      "\n",
      "tmp_path -- ...\\_pytest\\tmpdir.py:198\n",
      "    Return a temporary directory path object which is unique to each test\n",
      "    function invocation, created as a sub directory of the base temporary\n",
      "    directory.\n",
      "\n",
      "\n",
      "------------------ fixtures defined from anyio.pytest_plugin ------------------\n",
      "anyio_backend -- ..\\..\\..\\..\\Anaconda3\\envs\\venv_pluralSight\\lib\\site-packages\\anyio\\pytest_plugin.py:135\n",
      "    no docstring available\n",
      "\n",
      "anyio_backend_name -- ..\\..\\..\\..\\Anaconda3\\envs\\venv_pluralSight\\lib\\site-packages\\anyio\\pytest_plugin.py:140\n",
      "    no docstring available\n",
      "\n",
      "anyio_backend_options -- ..\\..\\..\\..\\Anaconda3\\envs\\venv_pluralSight\\lib\\site-packages\\anyio\\pytest_plugin.py:148\n",
      "    no docstring available\n",
      "\n",
      "\n",
      "=================================== ERRORS ====================================\n",
      "________________________ ERROR collecting test session ________________________\n",
      "..\\..\\..\\..\\Anaconda3\\envs\\venv_pluralSight\\lib\\importlib\\__init__.py:127: in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "<frozen importlib._bootstrap>:1030: in _gcd_import\n",
      "    ???\n",
      "<frozen importlib._bootstrap>:1007: in _find_and_load\n",
      "    ???\n",
      "<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n",
      "    ???\n",
      "<frozen importlib._bootstrap>:680: in _load_unlocked\n",
      "    ???\n",
      "..\\..\\..\\..\\Anaconda3\\envs\\venv_pluralSight\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:168: in exec_module\n",
      "    exec(co, module.__dict__)\n",
      "UnitTestProject\\04\\demos\\phonebook_pytest2\\tests\\conftest.py:5: in <module>\n",
      "    from phonebook.phonenumbers import Phonebook\n",
      "E   ModuleNotFoundError: No module named 'phonebook'\n",
      "=========================== short test summary info ===========================\n",
      "ERROR  - ModuleNotFoundError: No module named 'phonebook'\n",
      "============================== 1 error in 0.17s ===============================\n"
     ]
    }
   ],
   "source": [
    "!pytest --fixtures # lists all available built-in or created fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051fe39-3268-480a-99b7-efd50af610aa",
   "metadata": {},
   "source": [
    "### Doctest\n",
    "Doctest is a module that allows us to write tests directly in the docstring of methods\n",
    "The best sue cases are for:\n",
    "> maintaining docstrings  \n",
    "regression testing  \n",
    "tutorial documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6228fcfe-58cc-4cca-8b13-9251246ec43c",
   "metadata": {},
   "source": [
    "To handle output that changes with each running of the test, derived of random events or different system paths we can use elipsis `...` as a wildcard that will accept any value. However best is to change the code so the output is constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b1fe744-574a-45ad-a9f7-d78dc976d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def do_dice_rolling(input_source=input):\n",
    "    \"\"\"\n",
    "    Interactive command-line dice rolling.\n",
    "    Roll 5 dice and present them to the user. Allow the user to re-roll up to twice.\n",
    "\n",
    "    :return: the final 5 dice that were rolled\n",
    "\n",
    "    >>> random.seed(1234)\n",
    "    >>> do_dice_rolling(_reroll_nothing)\n",
    "    Your roll is:\n",
    "    [1, 1, 1, 4, 5]\n",
    "    [1, 1, 1, 4, 5]\n",
    "    [1, 1, 1, 4, 5]\n",
    "    [1, 1, 1, 4, 5]\n",
    "    >>> do_dice_rolling(_reroll_everything)\n",
    "    Your roll is:\n",
    "    [1, 1, 1, 6, 6]\n",
    "    [1, 1, 2, 3, 6]\n",
    "    [1, 1, 1, 1, 3]\n",
    "    [1, 1, 1, 1, 3]\n",
    "    \"\"\"\n",
    "    print(\"Your roll is:\")\n",
    "    dice = roll()\n",
    "    print(dice)\n",
    "    re_rolls_left = 2\n",
    "    while re_rolls_left:\n",
    "        try:\n",
    "            to_re_roll = input_source(\"Which dice will you re-roll?\\n\")\n",
    "            new_dice = re_roll(dice[:], convert_input_to_dice(to_re_roll))\n",
    "        except ValueError:\n",
    "            print(\"invalid re-roll choice. Please enter a comma separated list of dice eg 1,2\")\n",
    "            continue\n",
    "        print(new_dice)\n",
    "        re_rolls_left -= 1\n",
    "        dice = new_dice\n",
    "    return dice\n",
    "\n",
    "\n",
    "def pair(dice):\n",
    "    \"\"\"Score the given roll in the 'Pair' category\n",
    "\n",
    "    >>> pair([1,2,3,4,4])\n",
    "    8\n",
    "    >>> pair([1,2,3,4,5])\n",
    "    0\n",
    "\n",
    "    It uses the highest scoring pair if there is more than one pair\n",
    "\n",
    "    >>> pair([1,3,3,4,4])\n",
    "    8\n",
    "    >>> pair([3,3,3,4,4])\n",
    "    8\n",
    "    \"\"\"\n",
    "    counts = dice_counts(dice)\n",
    "    for i in [6, 5, 4, 3, 2, 1]:\n",
    "        if counts[i] >= 2:\n",
    "            return 2 * i\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "967cd505-1ad8-47fc-8dd5-cde8cc15f649",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    random.seed(1234)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    do_dice_rolling(_reroll_nothing)\n",
      "Expecting:\n",
      "    Your roll is:\n",
      "    [1, 1, 1, 4, 5]\n",
      "    [1, 1, 1, 4, 5]\n",
      "    [1, 1, 1, 4, 5]\n",
      "    [1, 1, 1, 4, 5]\n",
      "**********************************************************************\n",
      "File \"__main__\", line 11, in __main__.do_dice_rolling\n",
      "Failed example:\n",
      "    do_dice_rolling(_reroll_nothing)\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\goncalo.felicio\\Anaconda3\\envs\\venv_pluralSight\\lib\\doctest.py\", line 1334, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest __main__.do_dice_rolling[1]>\", line 1, in <module>\n",
      "        do_dice_rolling(_reroll_nothing)\n",
      "    NameError: name '_reroll_nothing' is not defined\n",
      "Trying:\n",
      "    do_dice_rolling(_reroll_everything)\n",
      "Expecting:\n",
      "    Your roll is:\n",
      "    [1, 1, 1, 6, 6]\n",
      "    [1, 1, 2, 3, 6]\n",
      "    [1, 1, 1, 1, 3]\n",
      "    [1, 1, 1, 1, 3]\n",
      "**********************************************************************\n",
      "File \"__main__\", line 17, in __main__.do_dice_rolling\n",
      "Failed example:\n",
      "    do_dice_rolling(_reroll_everything)\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\goncalo.felicio\\Anaconda3\\envs\\venv_pluralSight\\lib\\doctest.py\", line 1334, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest __main__.do_dice_rolling[2]>\", line 1, in <module>\n",
      "        do_dice_rolling(_reroll_everything)\n",
      "    NameError: name '_reroll_everything' is not defined\n",
      "Trying:\n",
      "    pair([1,2,3,4,4])\n",
      "Expecting:\n",
      "    8\n",
      "**********************************************************************\n",
      "File \"__main__\", line 44, in __main__.pair\n",
      "Failed example:\n",
      "    pair([1,2,3,4,4])\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\goncalo.felicio\\Anaconda3\\envs\\venv_pluralSight\\lib\\doctest.py\", line 1334, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest __main__.pair[0]>\", line 1, in <module>\n",
      "        pair([1,2,3,4,4])\n",
      "      File \"C:\\Users\\goncalo.felicio\\AppData\\Local\\Temp\\ipykernel_15960\\2255893215.py\", line 56, in pair\n",
      "        counts = dice_counts(dice)\n",
      "    NameError: name 'dice_counts' is not defined\n",
      "Trying:\n",
      "    pair([1,2,3,4,5])\n",
      "Expecting:\n",
      "    0\n",
      "**********************************************************************\n",
      "File \"__main__\", line 46, in __main__.pair\n",
      "Failed example:\n",
      "    pair([1,2,3,4,5])\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\goncalo.felicio\\Anaconda3\\envs\\venv_pluralSight\\lib\\doctest.py\", line 1334, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest __main__.pair[1]>\", line 1, in <module>\n",
      "        pair([1,2,3,4,5])\n",
      "      File \"C:\\Users\\goncalo.felicio\\AppData\\Local\\Temp\\ipykernel_15960\\2255893215.py\", line 56, in pair\n",
      "        counts = dice_counts(dice)\n",
      "    NameError: name 'dice_counts' is not defined\n",
      "Trying:\n",
      "    pair([1,3,3,4,4])\n",
      "Expecting:\n",
      "    8\n",
      "**********************************************************************\n",
      "File \"__main__\", line 51, in __main__.pair\n",
      "Failed example:\n",
      "    pair([1,3,3,4,4])\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\goncalo.felicio\\Anaconda3\\envs\\venv_pluralSight\\lib\\doctest.py\", line 1334, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest __main__.pair[2]>\", line 1, in <module>\n",
      "        pair([1,3,3,4,4])\n",
      "      File \"C:\\Users\\goncalo.felicio\\AppData\\Local\\Temp\\ipykernel_15960\\2255893215.py\", line 56, in pair\n",
      "        counts = dice_counts(dice)\n",
      "    NameError: name 'dice_counts' is not defined\n",
      "Trying:\n",
      "    pair([3,3,3,4,4])\n",
      "Expecting:\n",
      "    8\n",
      "**********************************************************************\n",
      "File \"__main__\", line 53, in __main__.pair\n",
      "Failed example:\n",
      "    pair([3,3,3,4,4])\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\goncalo.felicio\\Anaconda3\\envs\\venv_pluralSight\\lib\\doctest.py\", line 1334, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest __main__.pair[3]>\", line 1, in <module>\n",
      "        pair([3,3,3,4,4])\n",
      "      File \"C:\\Users\\goncalo.felicio\\AppData\\Local\\Temp\\ipykernel_15960\\2255893215.py\", line 56, in pair\n",
      "        counts = dice_counts(dice)\n",
      "    NameError: name 'dice_counts' is not defined\n",
      "Trying:\n",
      "    three_of_a_kind([1,1,5,5,5])\n",
      "Expecting:\n",
      "    15\n",
      "**********************************************************************\n",
      "File \"__main__\", line 66, in __main__.three_of_a_kind\n",
      "Failed example:\n",
      "    three_of_a_kind([1,1,5,5,5])\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\goncalo.felicio\\Anaconda3\\envs\\venv_pluralSight\\lib\\doctest.py\", line 1334, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest __main__.three_of_a_kind[0]>\", line 1, in <module>\n",
      "        three_of_a_kind([1,1,5,5,5])\n",
      "      File \"C:\\Users\\goncalo.felicio\\AppData\\Local\\Temp\\ipykernel_15960\\1080533351.py\", line 73, in three_of_a_kind\n",
      "        counts = dice_counts(dice)\n",
      "    NameError: name 'dice_counts' is not defined\n",
      "Trying:\n",
      "    three_of_a_kind([1,5,5,5,5])\n",
      "Expecting:\n",
      "    15\n",
      "**********************************************************************\n",
      "File \"__main__\", line 68, in __main__.three_of_a_kind\n",
      "Failed example:\n",
      "    three_of_a_kind([1,5,5,5,5])\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\goncalo.felicio\\Anaconda3\\envs\\venv_pluralSight\\lib\\doctest.py\", line 1334, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest __main__.three_of_a_kind[1]>\", line 1, in <module>\n",
      "        three_of_a_kind([1,5,5,5,5])\n",
      "      File \"C:\\Users\\goncalo.felicio\\AppData\\Local\\Temp\\ipykernel_15960\\1080533351.py\", line 73, in three_of_a_kind\n",
      "        counts = dice_counts(dice)\n",
      "    NameError: name 'dice_counts' is not defined\n",
      "Trying:\n",
      "    three_of_a_kind([1,2,3,4,5])\n",
      "Expecting:\n",
      "    0\n",
      "**********************************************************************\n",
      "File \"__main__\", line 70, in __main__.three_of_a_kind\n",
      "Failed example:\n",
      "    three_of_a_kind([1,2,3,4,5])\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\Users\\goncalo.felicio\\Anaconda3\\envs\\venv_pluralSight\\lib\\doctest.py\", line 1334, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest __main__.three_of_a_kind[2]>\", line 1, in <module>\n",
      "        three_of_a_kind([1,2,3,4,5])\n",
      "      File \"C:\\Users\\goncalo.felicio\\AppData\\Local\\Temp\\ipykernel_15960\\1080533351.py\", line 73, in three_of_a_kind\n",
      "        counts = dice_counts(dice)\n",
      "    NameError: name 'dice_counts' is not defined\n",
      "11 items had no tests:\n",
      "    __main__\n",
      "    __main__.Phonebook\n",
      "    __main__.Phonebook.__init__\n",
      "    __main__.Phonebook.add\n",
      "    __main__.Phonebook.clear\n",
      "    __main__.Phonebook.lookup\n",
      "    __main__.Phonebook.names\n",
      "    __main__.phonebook\n",
      "    __main__.test_lookup_by_name\n",
      "    __main__.test_missing_name_raises_error\n",
      "    __main__.test_phonebook_contains_all_names\n",
      "**********************************************************************\n",
      "3 items had failures:\n",
      "   2 of   3 in __main__.do_dice_rolling\n",
      "   4 of   4 in __main__.pair\n",
      "   3 of   3 in __main__.three_of_a_kind\n",
      "10 tests in 14 items.\n",
      "1 passed and 9 failed.\n",
      "***Test Failed*** 9 failures.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=9, attempted=10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.testmod(verbose=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541be120-3aeb-4f32-8479-6823579d14e0",
   "metadata": {},
   "source": [
    "### Test Doubles\n",
    "Test doubles is somethign that replaces a collaborator of the unit code we are testing  \n",
    "The most common ones are Stub and Spy  \n",
    "We use a test double when the collaborator is hard to run or slow and would impair our testing ability or we can also use a test double to assert certain method calls on the collaborator  \n",
    "We can inject test doubles with Monkeypatching when there isn't an easier way to do it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea214a75-58eb-49bb-aeaa-69316ad620ef",
   "metadata": {},
   "source": [
    "### Parameterised Tests\n",
    "Parameterised tests is a way to increase test coverage without adding very much new code, in a way it is a refactoring of the test cases, rather than the production code  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a80df-7f33-4bec-8a8c-ace297fd0ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\"player1_points, player2_points, expected_score\",\n",
    "                         [(0, 0, \"Love-All\"),\n",
    "                          (1, 1, \"Fifteen-All\"),\n",
    "                          (2, 2, \"Thirty-All\"),\n",
    "                          (2, 1, \"Thirty-Fifteen\"),\n",
    "                          (3, 1, \"Forty-Fifteen\"),\n",
    "                          (4, 1, \"Win for Player 1\"),\n",
    "                          (4, 3, \"Advantage Player 1\"),\n",
    "                          (4, 5, \"Advantage Player 2\"),\n",
    "                          ])\n",
    "def test_score_tennis(player1_points, player2_points, expected_score):\n",
    "    assert score_tennis(player1_points, player2_points) == expected_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7dacb5-5640-4f1c-9e17-e2ae1606fabb",
   "metadata": {},
   "source": [
    "We can also measure test coverage to analyse our code, this is useful when we are developing new code and respective tests, when we add tests to code that we might not understand, and when we are tracking trends over time and assessing the health of our test suite  \n",
    "However we should be careful with coverage results, as they don't necessarily reflect the quality of our code, they only measure how covered the existing code is by our tests, it is not a very smart tool, even though it appears so"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
